{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is PyTorch?<br/>\n",
    "Itâ€™s a Python-based scientific computing package targeted at two sets of audiences:\n",
    "<ul>\n",
    "    <li>Pytorch Tensors are much much faster than numpy arrays, Hence they are much more used than numpy arrays\n",
    "    <li> A Tensor is same as an array in numpy, Just that how pytorch makes use of it, makes it faster than numpy\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 1.0599e-35],\n",
      "        [1.4013e-45, 1.4013e-45, 2.3329e-18],\n",
      "        [0.0000e+00, 0.0000e+00, 7.0368e+28],\n",
      "        [3.3127e-18, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "'''An uninitialized matrix is declared,but does not contain definite known values before it is used.When uninitialized \n",
    "matrix is created, whatever values were in the allocated memory at the time will appear as the initial values.'''\n",
    "x = torch.empty(5, 3)  \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3410, 0.7873, 0.6060],\n",
      "        [0.4813, 0.5173, 0.4139],\n",
      "        [0.8591, 0.1049, 0.6021],\n",
      "        [0.8551, 0.8041, 0.8034],\n",
      "        [0.5794, 0.5891, 0.4918]])\n"
     ]
    }
   ],
   "source": [
    "'''Constructs a randomly initialized matrix, This idea and the idea above will be used to generate data while we will\n",
    "try to create model and train them on some synthetic data'''\n",
    "x = torch.rand(5, 3)   \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "'''Pretty obvious when you need a matrix of zeros of datatype \"long\" denoted as dtype you can use torch.zeros'''\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "'''Constructing a tensor from a list is important to know and understand as often you will process and keep data in a \n",
    "list which will be easy, but then in order to make operations faster you can change their type to pytorch tensors'''\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5190, -0.3949])\n"
     ]
    }
   ],
   "source": [
    "'''Creating a tensor \"based on existing tensor\" this can come in to be useful when you need mock data based on \n",
    "some true data, so that you can create somewhat similar data and train your model on the mock data, by somewhat \n",
    "similar data i mean data will be similar in terms of\n",
    "        a) The shape of tensor\n",
    "        b) Data-type (float or int or whatever)\n",
    "There is no gurantee that the data will also follow the distribution that original data is following\n",
    "'''\n",
    "x = torch.randn_like(x, dtype=torch.float) \n",
    "print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''In numpy we have the shape method on arrays, in pytorch we have the size method to get the dimensions of the array'''\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of addition of x and y: tensor([3, 4])\n",
      "result of subtraction of x and y: tensor([-1,  0])\n",
      "result of addition of x and y where y is broadcasted: tensor([3, 4])\n"
     ]
    }
   ],
   "source": [
    "'''Performing operations on tensors with comments and outputs are as shown below'''\n",
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([2,2])\n",
    "print('result of addition of x and y:',x+y)\n",
    "print('result of subtraction of x and y:',x-y)\n",
    "y = torch.tensor([2])\n",
    "print('result of addition of x and y where y is broadcasted:',x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''storing outputs in variables can be accomplished in multiple ways'''\n",
    "result = torch.empty(1,2, dtype = torch.long)\n",
    "torch.add(x,y, out = result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not just one way to do the addition operation or any other operation on torch, example you can be using the 'add' method in the torch class and then there are multiple other methods, So based on the requirement you can use whatver suits you best.<br><br>\n",
    "A syntax rule in pytorch: Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''By Default in pytorch inplace=True means that it will modify the input directly, without allocating any additional \n",
    "output. It can sometimes slightly decrease the memory usage, but may not always be a valid operation (because the \n",
    "original input is destroyed). Here is an example of inplace operation in pytorch'''\n",
    "x = torch.tensor([1,2])\n",
    "x.add_(torch.tensor([1]))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8788, 0.3547, 0.8602],\n",
      "        [0.1516, 0.5547, 0.8395],\n",
      "        [0.8102, 0.9294, 0.7232],\n",
      "        [0.0176, 0.2607, 0.7768],\n",
      "        [0.9836, 0.4264, 0.4823]])\n",
      "tensor([[0.1516, 0.5547]])\n"
     ]
    }
   ],
   "source": [
    "'''How can you convert to and fro and use numpy with torch'''\n",
    "x = torch.rand(5,3,dtype=torch.float)\n",
    "print(x)\n",
    "print(x[1:2,:2])   #supports numpy like indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.4689e-01, 6.5386e-01, 1.2796e-01, 4.6577e-02],\n",
       "         [5.2342e-01, 4.9816e-01, 5.3529e-01, 1.3891e-01],\n",
       "         [7.8292e-01, 2.6357e-01, 1.0029e-01, 3.3866e-01],\n",
       "         [6.0859e-01, 6.9761e-04, 9.9993e-01, 2.0291e-01]]),\n",
       " tensor([3.4689e-01, 6.5386e-01, 1.2796e-01, 4.6577e-02, 5.2342e-01, 4.9816e-01,\n",
       "         5.3529e-01, 1.3891e-01, 7.8292e-01, 2.6357e-01, 1.0029e-01, 3.3866e-01,\n",
       "         6.0859e-01, 6.9761e-04, 9.9993e-01, 2.0291e-01]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''You are already familier with np.reshape the torch equivalent is \"view\" array.view(shape tuple)'''\n",
    "x = torch.rand(4,4)\n",
    "y = x.view(16)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We define actual dimensions in torch:\n",
      " tensor([[3.4689e-01, 6.5386e-01, 1.2796e-01, 4.6577e-02, 5.2342e-01, 4.9816e-01,\n",
      "         5.3529e-01, 1.3891e-01],\n",
      "        [7.8292e-01, 2.6357e-01, 1.0029e-01, 3.3866e-01, 6.0859e-01, 6.9761e-04,\n",
      "         9.9993e-01, 2.0291e-01]])\n",
      "\n",
      " We let torch infer dimensions on its own by giving -1: \n",
      " tensor([[3.4689e-01, 6.5386e-01, 1.2796e-01, 4.6577e-02, 5.2342e-01, 4.9816e-01,\n",
      "         5.3529e-01, 1.3891e-01],\n",
      "        [7.8292e-01, 2.6357e-01, 1.0029e-01, 3.3866e-01, 6.0859e-01, 6.9761e-04,\n",
      "         9.9993e-01, 2.0291e-01]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(2,8)\n",
    "print('We define actual dimensions in torch:\\n',z)\n",
    "'''The same operation can also be performed as shown below, -1 to torch means that infer the other dimension \n",
    "automatically from the shape or size of the parent array'''\n",
    "z = x.view(-1,8)\n",
    "print('\\n We let torch infer dimensions on its own by giving -1: \\n',z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "'''Converting a torch tensor to a numpy and vice-versa'''\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(type(a),type(b))\n",
    "'''Point to notice below is that, The Torch Tensor and NumPy array will share their underlying memory locations \n",
    "(if the Torch Tensor is on CPU), and changing one will change the other. Notice operation is only performed\n",
    "on torch tensor but changes reflect in numpy version as well, this is because they share the same memory'''\n",
    "a = a.add_(1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "'''We have already seen how to convert a torch tensor to numpy now how to convert a numpy to torch tensor'''\n",
    "import numpy as np\n",
    "np_arr = np.ones(5)\n",
    "b = torch.from_numpy(np_arr)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Moving tensors, model or any other object in and out of a device for computations, example: We want the computation \n",
    "to be only on cpu, we put all the things on cpu, we want all the computation on gpu we put all on gpu'''\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "'''Here we have said that if cuda is available device=cuda else cpu'''\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8181, 0.6268, 0.5058, 0.2316],\n",
       "        [0.8425, 0.8170, 0.6712, 0.8997],\n",
       "        [0.9012, 0.6415, 0.3288, 0.5498]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,4)\n",
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note: If some of the data or model is on cpu and other on gpu, you will not able to communicate among them\\nyou will need everything to be on the same device in order to do any computations on them'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Note: If some of the data or model is on cpu and other on gpu, you will not able to communicate among them\n",
    "you will need everything to be on the same device in order to do any computations on them'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
