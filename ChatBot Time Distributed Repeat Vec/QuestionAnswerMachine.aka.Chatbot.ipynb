{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Chatbot Implementation </h2>\n",
    "<br>\n",
    "This is the classic case of a QnA machine based on answers, But this is all the basics that you need in order to build a chatbot! A context Based Chatbot!\n",
    "\n",
    "How?\n",
    "\n",
    "So in this case we pass in the question to get the answer! One thing that will improve the model which i did not do due to memory constraint was 'one-hot-encoding' of the output vector. Armed with One-Hot-Encoding the model is programmed to pick it up from there itself. \n",
    "\n",
    "Passing the Context!\n",
    "Initially start with a 60 time step thing! with the first vector as having all values that have been asked lets say \n",
    "\n",
    "1) How are you? <-- this is the first statement hence in our 60 time steps vector, this becomes the step 1<br>\n",
    "2) I am good what about you? <-- if this was the reply then in next step we will have 2 vectors with values in them and other 58 filled with 0s\n",
    "<br>\n",
    "\n",
    "Hence we can keep passing the context to the future time steps and so on and hence this becomes a context based chatbot, Also you can improve it with\n",
    "<br>\n",
    "1) Bidirectional LSTM<br>\n",
    "2) Batch Normalization<br>\n",
    "3) Dropout\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras import Sequential\n",
    "from keras.layers import RepeatVector\n",
    "import numpy as np\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionID</th>\n",
       "      <th>Question</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>DocumentTitle</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Q274</td>\n",
       "      <td>what happens at the end of toy story 3</td>\n",
       "      <td>D273</td>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>D273-14</td>\n",
       "      <td>It is currently the 10th-highest-grossing film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>Q602</td>\n",
       "      <td>how many blind people are there in the us</td>\n",
       "      <td>D591</td>\n",
       "      <td>Blindness</td>\n",
       "      <td>D591-13</td>\n",
       "      <td>Blindness is defined as visual acuity of less ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>Q499</td>\n",
       "      <td>how many rounds in boxing</td>\n",
       "      <td>D492</td>\n",
       "      <td>Boxing</td>\n",
       "      <td>D492-0</td>\n",
       "      <td>Boxing (pugilism, prize fighting, the sweet sc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>Q527</td>\n",
       "      <td>what happened in the 90's</td>\n",
       "      <td>D519</td>\n",
       "      <td>1990s</td>\n",
       "      <td>D519-1</td>\n",
       "      <td>It was the 10th and last decade of the 20th ce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>Q298</td>\n",
       "      <td>what does a roman numeral L stand for?</td>\n",
       "      <td>D297</td>\n",
       "      <td>Roman numerals</td>\n",
       "      <td>D297-1</td>\n",
       "      <td>Roman numerals, the numeric system in ancient ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     QuestionID                                   Question DocumentID  \\\n",
       "1999       Q274     what happens at the end of toy story 3       D273   \n",
       "4288       Q602  how many blind people are there in the us       D591   \n",
       "3598       Q499                  how many rounds in boxing       D492   \n",
       "3722       Q527                  what happened in the 90's       D519   \n",
       "2212       Q298     what does a roman numeral L stand for?       D297   \n",
       "\n",
       "       DocumentTitle SentenceID  \\\n",
       "1999     Toy Story 3    D273-14   \n",
       "4288       Blindness    D591-13   \n",
       "3598          Boxing     D492-0   \n",
       "3722           1990s     D519-1   \n",
       "2212  Roman numerals     D297-1   \n",
       "\n",
       "                                               Sentence  Label  \n",
       "1999  It is currently the 10th-highest-grossing film...      0  \n",
       "4288  Blindness is defined as visual acuity of less ...      0  \n",
       "3598  Boxing (pugilism, prize fighting, the sweet sc...      0  \n",
       "3722  It was the 10th and last decade of the 20th ce...      0  \n",
       "2212  Roman numerals, the numeric system in ancient ...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('WikiQA-train.tsv')\n",
    "df = df[:10000]\n",
    "df = shuffle(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Question'] = df['Question'].str.lower()\n",
    "df['Sentence'] = df['Sentence'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Question'].values\n",
    "Y = df['Sentence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = dict()\n",
    "max_x = 0\n",
    "max_y = 0\n",
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for i in range(len(X)):\n",
    "    X[i] = tokenizer.tokenize(X[i])\n",
    "    \n",
    "    for j in range(len(X[i])):\n",
    "        if X[i][j] in word_dict:\n",
    "            X[i][j] = word_dict[X[i][j]]\n",
    "        else:\n",
    "            word_dict[X[i][j]] = index \n",
    "            X[i][j] = word_dict[X[i][j]]\n",
    "            index = index + 1\n",
    "        if len(X[i]) > max_x:\n",
    "            max_x = len(X[i])\n",
    "            temp_x = (len(X[i]),i)\n",
    "        \n",
    "    Y[i] = tokenizer.tokenize(Y[i])\n",
    "    for k in range(len(Y[i])):\n",
    "        if Y[i][k] in word_dict:\n",
    "            Y[i][k] = word_dict[Y[i][k]]\n",
    "        else:\n",
    "            word_dict[Y[i][k]] = index \n",
    "            Y[i][k] = word_dict[Y[i][k]]\n",
    "            index = index + 1\n",
    "            \n",
    "        if len(Y[i]) > max_y:\n",
    "            max_y = len(Y[i])\n",
    "            temp_y = (len(Y[i]), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_inv_map = {v: k for k, v in word_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X, maxlen=max_x,padding='post')\n",
    "Y_train = sequence.pad_sequences(Y, maxlen=max_y,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    2,    3, ...,    0,    0,    0],\n",
       "       [  19,   20,   21, ...,    0,    0,    0],\n",
       "       [  19,   20,   51, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  19,   20, 2466, ...,    0,    0,    0],\n",
       "       [  19,   20, 2155, ...,    0,    0,    0],\n",
       "       [  19,  251,   11, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for i in range(len(Y_train)):\n",
    "    Y.append([[j] for j in Y_train[i]])\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14497"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(words_inv_map.keys())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 19, 32)            463904    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 305, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 305, 256)          365568    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 305, 1)            257       \n",
      "=================================================================\n",
      "Total params: 882,929\n",
      "Trainable params: 882,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#30913\n",
    "model = Sequential()\n",
    "model.add(Embedding(list(words_inv_map.keys())[-1], 32, input_length=X_train.shape[1], mask_zero=True ))\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(RepeatVector(Y_train.shape[1]))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(Y.shape[2])))                \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " - 69s - loss: -2.4352e+03 - acc: 0.0418\n",
      "Epoch 2/1000\n",
      " - 68s - loss: -2.6863e+03 - acc: 1.7705e-05\n",
      "Epoch 3/1000\n",
      " - 70s - loss: -2.6863e+03 - acc: 1.5738e-05\n",
      "Epoch 4/1000\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y, epochs=1000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
